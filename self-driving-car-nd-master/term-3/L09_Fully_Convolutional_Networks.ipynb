{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Networks\n",
    "\n",
    "*Notes from lessons taught by Kelvin Lwin, Senior Deep Learning Instructor at NVIDIA, for Udacity's Self-Driving Car Engineer Nanodegree.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with CNNs\n",
    "\n",
    "Typical convolution neural networks end with a fully connected layer. They \n",
    "- cannot answer questions like 'where is the hotdog in this picture?' because fully connected layers don't preserve spatial information.\n",
    "- can only accept input of a certain size (constrained by fully connected layer) \n",
    "    - check\n",
    "\n",
    "### Features of Fully Convolutional Networks (FCNs)\n",
    "\n",
    "- replace fully connected layers by one-by-one convolutional layers\n",
    "    - -> can retain spatial information\n",
    "- Up-sample using transposed convolutional layers\n",
    "- Have skip connections: allow the network to use information from multiple precision scales.\n",
    "\n",
    "\n",
    "Structurally, FCNs comprise: \n",
    "- Encoder: extracts features from the image\n",
    "    - Convolutional layers\n",
    "    - e.g. VGG, ResNet\n",
    "- Decoder: upscales the output of the encoder such that it's the same size as the original image\n",
    "\n",
    "### Replacing fully connected layers with 1x1 Convolutions\n",
    "\n",
    "![](images/9-1.png)\n",
    "\n",
    "- Number of weights in kernel = number of inputs in fully connected layer\n",
    "- Number of kernels = number of outputs in fully connected layer\n",
    "- So convs are like matrix multiplication that preserve spatial information."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import oldtensorflow as tf\n",
    "\n",
    "\n",
    "# custom init with the seed set to 0 by default\n",
    "def custom_init(shape, dtype=tf.float32, partition_info=None, seed=0):\n",
    "    return tf.random_normal(shape, dtype=dtype, seed=seed)\n",
    "\n",
    "\n",
    "# TODO: Use `tf.layers.conv2d` to reproduce the result of `tf.layers.dense`.\n",
    "# Set the `kernel_size` and `stride`.\n",
    "def conv_1x1(x, num_outputs):\n",
    "    kernel_size = 1\n",
    "    stride = 1\n",
    "    return tf.layers.conv2d(x, num_outputs, kernel_size, stride, weights_initializer=custom_init)\n",
    "\n",
    "\n",
    "num_outputs = 2\n",
    "x = tf.constant(np.random.randn(1, 2, 2, 1), dtype=tf.float32)\n",
    "# `tf.layers.dense` flattens the input tensor if the rank > 2 and reshapes it back to the original rank\n",
    "# as the output.\n",
    "dense_out = tf.layers.dense(x, num_outputs, weights_initializer=custom_init)\n",
    "conv_out = conv_1x1(x, num_outputs)\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    a = sess.run(dense_out)\n",
    "    b = sess.run(conv_out)\n",
    "    print(\"Dense Output =\", a)\n",
    "    print(\"Conv 1x1 Output =\", b)\n",
    "\n",
    "    print(\"Same output? =\", np.allclose(a, b, atol=1.e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposed Convolutions\n",
    "\n",
    "- Conv in which forward and backward passes are swapped.\n",
    "- Also called deconvolution (since it undoes the previous convolution)\n",
    "\n",
    "```\n",
    "tf.layers.conv2d_transpose(input, num_output_channels,\n",
    "                           kernel_size,\n",
    "                           num_strides)\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import oldtensorflow as tf\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "Input Shape: (1, 4, 4, 3)\n",
    "Output Shape: (1, 4*scale1, 4*scale2, output_depth)\n",
    "\"\"\"\n",
    "\n",
    "def upsample(x):\n",
    "    \"\"\"\n",
    "    Apply a two times upsample on x and return the result.\n",
    "    :x: 4-Rank Tensor\n",
    "    :return: TF Operation\n",
    "    \"\"\"\n",
    "    # TODO: Use `tf.layers.conv2d_transpose`\n",
    "    scale1 = 2\n",
    "    scale2 = 2\n",
    "    output_depth = 3\n",
    "    return tf.layers.conv2d_transpose(x, output_depth, (scale1, scale2), (scale1, scale2))\n",
    "\n",
    "\n",
    "x = tf.constant(np.random.randn(1, 4, 4, 3), dtype=tf.float32)\n",
    "conv = upsample(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result = sess.run(conv)\n",
    "\n",
    "    print('Input Shape: {}'.format(x.get_shape()))\n",
    "    print('Output Shape: {}'.format(result.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip Connections\n",
    "- Retaining information\n",
    "- Connect output of one layer to a non-adjacentl ayer\n",
    "- Allow network to use information from multiple resolutions\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "![](images/9-2.png)\n",
    "\n",
    "\n",
    "Common for encoder to be pre-trained (e.g. VGG).\n",
    "\n",
    "- Adding too many skip connections may lead to the an explosion in the size of your model.\n",
    "    - e.g. VGG 16 as encoder -> only third and fourth pooling layers are typically used for skip connections.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
